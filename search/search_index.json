{"config":{"lang":["en"],"separator":"[\\s\\-]+","pipeline":["stopWordFilter"]},"docs":[{"location":"","title":"DCR - Document Content Recognition","text":""},{"location":"#1-introduction","title":"1. Introduction","text":"<p>Based on the paper \"Unfolding the Structure of a Document using Deep Learning\" (Rahman and Finin, 2019), this software project attempts to use various software techniques to automatically recognise the structure in any <code>pdf</code> documents and thus make them more searchable.</p> <p>The processing logic is as follows:</p> <ul> <li>New documents are made available in the file directory <code>inbox</code>. If required, other language-related file directories can also be used (see section Document Language).</li> <li>Documents in a file format accepted by DCR are registered and moved to the file directory <code>\u00ecnbox_accepted</code>. All other documents are registered and moved to the file directory <code>\u00ecnbox_rejected</code>.</li> <li>Documents not in <code>pdf</code> format are converted to <code>pdf</code> format using Pandoc and TeX Live. </li> <li>Documents based on scanning which, therefore, do not contain text elements, are scanned and converted to <code>pdf</code> format using the Tesseract OCR software. This process applies to all image format files e.g. <code>jpeg</code>, <code>tiff</code> etc., as well as scanned images in <code>pdf</code> format.  </li> <li>From all <code>pdf</code> documents, the text and associated metadata is extracted into a document-specific <code>xml</code> file using PDFlib TET.</li> <li>The document-specific <code>xml</code> files are then parsed and the DCR-relevant contents are written to the <code>JSON</code> files. </li> <li>From the <code>JSON</code> file(s) spaCy extracts qualified tokens and stores them either in a <code>JSON</code> file or in the database table <code>token</code>.</li> </ul>"},{"location":"#11-rahman-finin-paper","title":"1.1 Rahman &amp; Finin Paper","text":""},{"location":"#12-supported-file-types","title":"1.2 Supported File Types","text":"<p>DCR can handle the following file types based on the file extension:</p> <ul> <li><code>bmp</code> bitmap image file</li> <li><code>csv</code> comma-separated values</li> <li><code>docx</code> Office Open XML</li> <li><code>epub</code> e-book file format</li> <li><code>gif</code> Graphics Interchange Format</li> <li><code>html</code> HyperText Markup Language</li> <li><code>jp2</code> JPEG 2000</li> <li><code>jpeg</code> Joint Photographic Experts Group</li> <li><code>odt</code> Open Document Format for Office Applications</li> <li><code>pdf</code> Portable Document Format</li> <li><code>png</code> Portable Network Graphics</li> <li><code>pnm</code> portable any-map format</li> <li><code>rst</code> reStructuredText (RST</li> <li><code>rtf</code> Rich Text Format</li> <li><code>tif</code> Tag Image File Format</li> <li><code>tiff</code> Tag Image File Format</li> <li><code>webp</code> Image file format with lossless and lossy compression</li> </ul>"},{"location":"#2-detailed-processing-actions","title":"2. Detailed Processing Actions","text":"<p>The documents to be processed are divided into individual steps, so-called actions.  Each action has the task of changing the state of a document by transforming an input file format into a different output file format. The database tables <code>run</code>, <code>document</code>, and <code>action</code> document the current state of a document, as well as the actions performed so far. If an error occurs during the processing of the document, this is recorded in the database tables <code>document</code> and <code>action</code>. During the next run with the same action, the faulty documents are also processed again.</p>"},{"location":"#21-preprocessor","title":"2.1 Preprocessor","text":""},{"location":"#211-preprocessor-architecture","title":"2.1.1 Preprocessor Architecture","text":""},{"location":"#212-process-the-inbox-directory-action-p_i","title":"2.1.2 Process the inbox directory (action: <code>p_i</code>)","text":"<p>In the first action, the file directory <code>inbox</code> is checked for new document files.  An entry is created in the <code>document</code> database table for each new document, showing the current processing status of the document. </p> <p>The association of document and language is managed via subdirectories of the file folder <code>inbox</code>.  In the database table <code>language</code>, the column <code>directory_name_inbox</code> specifies per language in which subdirectory the documents in this language are to be supplied.  Detailed information on this can be found in the chapter Running DCR in the section Document Language.</p> <p>The new document files are processed based on their file extension as follows:</p>"},{"location":"#2121-file-extension-pdf","title":"2.1.2.1 File extension <code>pdf</code>","text":"<p>The module <code>fitz</code> from package PyMuPDF is used to check whether the <code>pdf</code> document is a scanned image or not.  A <code>pdf</code> document consisting of a scanned image is marked for conversion from <code>pdf</code> format to an image format and moved to the file directory <code>\u00ecnbox_accepted</code>. Other <code>pdf</code> documents are marked for further processing with the <code>pdf</code> parser and then also moved to the file directory <code>\u00ecnbox_accepted</code>. If, however, when checking the <code>pdf</code> document with <code>fitz</code>, it turns out that the document with the file extension <code>pdf</code> is not really a <code>pdf</code> document, then the document is moved to the file directory <code>inbox_rejected</code>.</p>"},{"location":"#2122-file-extensions-of-documents-for-processing-with-pandoc-and-tex-live","title":"2.1.2.2 File extensions of documents for processing with Pandoc and TeX Live","text":"<p>Document files with the following file extensions are moved to the file directory <code>\u00ecnbox_accepted</code> and  marked for converting to <code>pdf</code> format using Pandoc and TeX Live:</p> <ul> <li><code>csv</code></li> <li><code>docx</code></li> <li><code>epub</code></li> <li><code>html</code></li> <li><code>odt</code></li> <li><code>rst</code></li> <li><code>rtf</code></li> </ul> <p>An exception are files with the file name <code>README.md</code>, which are ignored and not processed.</p>"},{"location":"#2123-file-extensions-of-documents-for-processing-with-tesseract-ocr","title":"2.1.2.3 File extensions of documents for processing with Tesseract OCR","text":"<p>Document files with the following file extensions are moved to the file directory <code>\u00ecnbox_accepted</code> and marked for converting to <code>pdf</code> format using Tesseract OCR:</p> <ul> <li><code>bmp</code></li> <li><code>gif</code></li> <li><code>jp2</code></li> <li><code>jpeg</code></li> <li><code>png</code></li> <li><code>pnm</code></li> <li><code>tif</code></li> <li><code>tiff</code></li> <li><code>webp</code></li> </ul>"},{"location":"#2124-other-file-extensions-of-documents","title":"2.1.2.4 Other file extensions of documents","text":"<p>Document files that do not fall into one of the previous categories are marked as faulty and moved to the file directory <code>\u00ecnbox_rejected</code>.</p>"},{"location":"#213-convert-pdf-documents-to-image-files-action-p_2_i","title":"2.1.3 Convert <code>pdf</code> documents to image files (action: <code>p_2_i</code>)","text":"<p>This processing action only has to be carried out if there are new <code>pdf</code> documents in the document input that only consist of scanned images. <code>pdf</code> documents consisting of scanned images must first be processed with OCR software in order to extract text they contain.  Since Tesseract OCR does not support the <code>pdf</code> file format, such a <code>pdf</code> document must first be converted into one or more image files.  This is done with the software pdf2image, which in turn is based on the Poppler software.</p> <p>The processing of the original document (parent document) is then completed and the further processing is carried out with the newly created image file(s) (child document(s)).</p> <p>Since an image file created here always contains only one page of a <code>pdf</code> document, a multi-page <code>pdf</code> document is distributed over several image files.  After processing with Tesseract OCR, these separated files are then combined into one <code>pdf</code> document.</p>"},{"location":"#214-convert-appropriate-image-files-to-pdf-files-action-ocr","title":"2.1.4 Convert appropriate image files to <code>pdf</code> files (action: <code>ocr</code>)","text":"<p>This processing action only has to be performed if there are new documents in the document entry that correspond to one of the document types listed in section 2.1.2.3. In this processing action, the documents of this document types are converted to the <code>pdf</code> format using Tesseract OCR.</p> <p>After processing with Tesseract OCR, the files split in the previous processing action are combined into a single <code>pdf</code> document.</p>"},{"location":"#215-convert-appropriate-non-pdf-documents-to-pdf-files-action-n_2_p","title":"2.1.5 Convert appropriate non-<code>pdf</code> documents to <code>pdf</code> files (action: <code>n_2_p</code>)","text":"<p>This processing action only has to be performed if there are new documents in the document entry that correspond to one of the document types listed in section 2.1.2.2. In this processing action, the documents of this document types are converted to <code>pdf</code> format using Pandoc and TeX Live.</p>"},{"location":"#22-nlp","title":"2.2 NLP","text":""},{"location":"#221-nlp-architecture","title":"2.2.1 NLP Architecture","text":""},{"location":"#222-extract-text-from-pdf-documents-action-tet","title":"2.2.2 Extract text from <code>pdf</code> documents (action: <code>tet</code>)","text":"<p>In this processing action, the text of the <code>pdf</code> documents from sections 2.1.2.1, 2.1.4 and 2.1.5 are extracted and written to <code>xml</code> files in <code>tetml</code> format for each document. The PDFlib TET library is used for this purpose.</p> <p>Depending on the configuration parameters <code>tetml_page</code> and <code>tetml_word</code>, up to three different <code>xml</code> files with different granularity can be created per document:</p> <ul> <li><code>tetml_line</code>: granularity document <code>line</code> (generated by default),</li> <li><code>tetml_page</code>: granularity document <code>page</code>,</li> <li><code>tetml_word</code>: granularity document <code>word</code>.</li> </ul> <p>The <code>page</code> variant and the <code>word</code> variant are both optional.</p> <p>Example extract from granularity <code>line</code>:</p> <pre><code>&lt;Pages&gt;\n&lt;Page number=\"1\" width=\"594.96\" height=\"840.96\"&gt;\n&lt;Options&gt;granularity=line&lt;/Options&gt;\n&lt;Content granularity=\"line\" dehyphenation=\"false\" dropcap=\"false\" font=\"false\" geometry=\"false\" shadow=\"false\" sub=\"false\" sup=\"false\"&gt;\n&lt;Para&gt;\n &lt;Box llx=\"26.45\" lly=\"818.96\" urx=\"485.41\" ury=\"826.96\"&gt;\n  &lt;Line llx=\"26.45\" lly=\"818.96\" urx=\"485.41\" ury=\"826.96\"&gt;\n   &lt;Text&gt;19/04/2020 https://www.sec.gov/Archives/edgar/data/821002/000157104917003132/t1700141_ex10-19.htm&lt;/Text&gt;\n  &lt;/Line&gt;\n &lt;/Box&gt;\n&lt;/Para&gt;\n</code></pre> <p>Example extract from granularity <code>page</code>:</p> <pre><code>&lt;Pages&gt;\n&lt;Page number=\"1\" width=\"594.96\" height=\"840.96\"&gt;\n&lt;Options&gt;granularity=page&lt;/Options&gt;\n&lt;Content granularity=\"page\" dehyphenation=\"false\" dropcap=\"false\" font=\"false\" geometry=\"false\" shadow=\"false\" sub=\"false\" sup=\"false\"&gt;\n&lt;Para&gt;\n &lt;Box llx=\"26.45\" lly=\"818.96\" urx=\"485.41\" ury=\"826.96\"&gt;\n  &lt;Text&gt;19/04/2020 https://www.sec.gov/Archives/edgar/data/821002/000157104917003132/t1700141_ex10-19.htm&lt;/Text&gt;\n &lt;/Box&gt;\n&lt;/Para&gt;\n</code></pre> <p>Example extract from granularity <code>word</code>:</p> <pre><code>&lt;Pages&gt;\n&lt;Page number=\"1\" width=\"594.96\" height=\"840.96\"&gt;\n&lt;Options&gt;granularity=word tetml={elements={line}}&lt;/Options&gt;\n&lt;Content granularity=\"word\" dehyphenation=\"false\" dropcap=\"false\" font=\"false\" geometry=\"false\" shadow=\"false\" sub=\"false\" sup=\"false\"&gt;\n&lt;Para&gt;\n &lt;Box llx=\"26.45\" lly=\"818.96\" urx=\"485.41\" ury=\"826.96\"&gt;\n  &lt;Line llx=\"26.45\" lly=\"818.96\" urx=\"485.41\" ury=\"826.96\"&gt;\n   &lt;Word&gt;\n    &lt;Text&gt;19&lt;/Text&gt;\n    &lt;Box llx=\"26.45\" lly=\"818.96\" urx=\"34.45\" ury=\"826.96\"/&gt;\n   &lt;/Word&gt;\n   &lt;Word&gt;\n    &lt;Text&gt;/&lt;/Text&gt;\n    &lt;Box llx=\"34.45\" lly=\"818.96\" urx=\"36.67\" ury=\"826.96\"/&gt;\n   &lt;/Word&gt;\n   &lt;Word&gt;\n    &lt;Text&gt;04&lt;/Text&gt;\n    &lt;Box llx=\"36.67\" lly=\"818.96\" urx=\"44.67\" ury=\"826.96\"/&gt;\n   &lt;/Word&gt;\n</code></pre>"},{"location":"#223-store-the-parser-result-in-a-json-file-action-s_p_j","title":"2.2.3 Store the parser result in a <code>JSON</code> file (action: <code>s_p_j</code>)","text":"<p>From the xml files of the granularity document <code>line</code> (<code>&lt;file_name&gt;_&lt;doc_id&gt;.line.xml</code>) or document <code>word</code> (<code>&lt;file_name&gt;_&lt;doc_id&gt;.word.xml</code>) created in the previous action, the text contained is now extracted with the existing metadata using xml parsing and stored in a <code>JSON</code> format in the database tables <code>content_tetml_line</code> and <code>content_tetml_word</code>.</p> <p>The document <code>line</code> granularity attempts to type the lines. Details on this process can be found in section 4.</p> <p>Example extract from granularity <code>line</code>:</p> <pre><code>{\n    \"documentId\": 1,\n    \"documentFileName\": \"Example.pdf\",\n    \"noLinesFooter\": 1,\n    \"noLinesHeader\": 1,\n    \"noLinesInDocument\": 2220,\n    \"noLinesToc\": 85,\n    \"noPagesInDocument\": 57,\n    \"noParagraphsInDocument\": 829,\n    \"noTablesInDocument\": 5,\n    \"pages\": [\n        {\n            \"pageNo\": 1,\n            \"noLinesInPage\": 15,\n            \"noParagraphsInPage\": 7,\n            \"lines\": [\n                {\n                    \"coordLLX\": 26.45,\n                    \"coordURX\": 485.41,\n                    \"lineIndexPage\": 0,\n                    \"lineIndexParagraph\": 0,\n                    \"lineNo\": 1,\n                    \"lineType\": \"h\",\n                    \"paragraphNo\": 1,\n                    \"text\": \"19/04/2020 https://www.sec.gov/Archives/edgar/data/821002/000157104917003132/t1700141_ex10-19.htm\"\n                },\n</code></pre> <p>Example extract from the optional file <code>line_list_bullet</code>:</p> <pre><code>{\n</code></pre> <p>Example extract from the optional file <code>line_list_number</code>:</p> <pre><code>{\n</code></pre> <p>Example extract from the optional file <code>line_table</code>:</p> <pre><code>{\n    \"documentId\": 1,\n    \"documentFileName\": \"Example.pdf\",\n    \"noTablesInDocument\": 5,\n    \"tables\": [\n        {\n            \"firstRowLLX\": 52.0,\n            \"firstRowURX\": 426.45,\n            \"noColumns\": 30,\n            \"noRows\": 10,\n            \"pageNoFrom\": 9,\n            \"pageNoTill\": 9,\n            \"tableNo\": 1,\n            \"rows\": [\n                {\n                    \"firstColumnLLX\": 52.0,\n                    \"lastColumnURX\": 426.45,\n                    \"noColumns\": 3,\n                    \"rowNo\": 1,\n                    \"columns\": [\n                        {\n                            \"columnNo\": 1,\n                            \"coordLLX\": 52.0,\n                            \"coordURX\": 63.77,\n                            \"lineIndexPage\": 18,\n                            \"lineIndexParagraph\": 0,\n                            \"lineNo\": 1,\n                            \"paragraphNo\": 4,\n                            \"text\": \"No.\"\n                        },\n</code></pre> <p>Example extract from the optional file <code>line_toc</code>:</p> <pre><code>{\n    \"documentId\": 1,\n    \"documentFileName\": \"Example.pdf\",\n    \"toc\": [\n        {\n            \"headingLevel\": 1,\n            \"headingText\": \"1. Lease Term: After the existing Tenant has vacated Landlord will allow Tenant to access the Demised\",\n            \"pageNo\": 4,\n            \"headingCtxLine1\": \"not delay or interfere with the completion of the Allowance Improvements by the Landlord in any material respect; and (b) prior to\",\n            \"headingCtxLine2\": \"entering the Demised Premises the Tenant shall provide insurance coverage as required by this Lease. Landlord shall offer the\",\n            \"headingCtxLine3\": \"existing tenant an early termination of its lease on December 31, 2011, instead of the normal expiration date of January 31, 2012.\",\n            \"regexp\": \"\\\\d+\\\\.$\"\n        },\n</code></pre> <p>Example extract from granularity <code>page</code>:</p> <pre><code>{\n    \"documentId\": 1,\n    \"documentFileName\": \"Example.pdf\",\n    \"noPagesInDocument\": 57,\n    \"noParagraphsInDocument\": 829,\n    \"pages\": [\n        {\n            \"pageNo\": 1,\n            \"noParagraphsInPage\": 7,\n            \"paragraphs\": [\n                {\n                    \"paragraphNo\": 1,\n                    \"text\": \"19/04/2020 https://www.sec.gov/Archives/edgar/data/821002/000157104917003132/t1700141_ex10-19.htm\"\n                },\n</code></pre> <p>Example extract from granularity <code>word</code>:</p> <pre><code>{\n    \"documentId\": 1,\n    \"documentFileName\": \"Example.pdf\",\n    \"noLinesInDocument\": 2217,\n    \"noPagesInDocument\": 57,\n    \"noParagraphsInDocument\": 828,\n    \"noWordsInDocument\": 38674,\n    \"pages\": [\n        {\n            \"pageNo\": 1,\n            \"noLinesInPage\": 15,\n            \"noParagraphsInPage\": 7,\n            \"noWordsInPage\": 112,\n            \"paragraphs\": [\n                {\n                    \"paragraphNo\": 1,\n                    \"noLinesInParagraph\": 1,\n                    \"noWordsInParagraph\": 28,\n                    \"lines\": [\n                        {\n                            \"lineNo\": 1,\n                            \"noWordsInLine\": 28,\n                            \"words\": [\n                                {\n                                    \"wordNo\": 1,\n                                    \"text\": \"19\"\n                                },\n</code></pre>"},{"location":"#224-create-qualified-document-tokens-action-tkn","title":"2.2.4 Create qualified document tokens (action: <code>tkn</code>)","text":"<p>For tokenization, spaCy is used. </p> <p>The document text is made available to spaCy page by page. Either the granularity document <code>line</code> or document <code>page</code> can be used for this. With the granularity document <code>line</code>, the recognised headers and footers are left out of the token creation.</p> <p>spaCy provides a number of attributes for the token.  Details can be found here in the spaCy documentation. The configuration parameters of the type <code>spacy_tkn_attr_...</code> control which of these attributes are stored to the database table <code>content_token</code>.</p> <p>In the event of an error, the original document is marked as erroneous and an explanatory entry is also written in the <code>document</code> table. </p> <p>Example extract from granularity <code>line</code>:</p> <pre><code>{\n    \"documentId\": 1,\n    \"documentFileName\": \"Example.pdf\",\n    \"noLinesFooter\": 1,\n    \"noLinesHeader\": 1,\n    \"noLinesInDocument\": 2031,\n    \"noLinesToc\": 85,\n    \"noPagesInDocument\": 57,\n    \"noParagraphsInDocument\": 630,\n    \"noSentencesInDocument\": 949,\n    \"noTablesInDocument\": 5,\n    \"noTokensInDocument\": 16495,\n    \"pages\": [\n        {\n            \"pageNo\": 1,\n            \"noLinesInPage\": 13,\n            \"noParagraphsInPage\": 5,\n            \"noSentencesInPage\": 5,\n            \"noTokensInPage\": 39,\n            \"paragraphs\": [\n                {\n                    \"paragraphNo\": 2,\n                    \"noLinesInParagraph\": 2,\n                    \"noSentencesInParagraph\": 1,\n                    \"noTokensInParagraph\": 7,\n                    \"sentences\": [\n                        {\n                            \"sentenceNo\": 1,\n                            \"coordLLX\": 34.0,\n                            \"coordURX\": 244.18,\n                            \"lineType\": \"b\",\n                            \"noTokensInSentence\": 7,\n                            \"text\": \"EX-10.19 3 t1700141_ex10-19.htm EXHIBIT 10.19 Exhibit 10.19\",\n                            \"tokens\": [\n                                {\n                                    \"tknI\": 0,\n                                    \"tknIsOov\": true,\n                                    \"tknLemma_\": \"ex-10.19\",\n                                    \"tknNorm_\": \"ex-10.19\",\n                                    \"tknPos_\": \"NUM\",\n                                    \"tknTag_\": \"CD\",\n                                    \"tknText\": \"EX-10.19\",\n                                    \"tknWhitespace_\": \" \"\n                                },\n</code></pre>"},{"location":"#3-auxiliary-file-names","title":"3. Auxiliary File Names","text":"<p>The processing actions are based on different flat files, each of which is generated from the original document on an action-related basis. Apart from the <code>JSON</code> files optionally created during the 'tokenizer' action, these can be automatically deleted after error-free processing.</p>"},{"location":"#31-naming-system","title":"3.1 Naming System","text":"<p>Action <code>p_i</code> - process the inbox directory</p> <pre><code>in : &lt;ost&gt;.&lt;oft&gt;              \nout: &lt;ost&gt;_&lt;di&gt;.&lt;oft&gt;\n</code></pre> <p>Action <code>p_2_i</code> - convert pdf documents to image files</p> <pre><code>in : &lt;ost&gt;_&lt;di&gt;.pdf                \nout: &lt;ost&gt;_&lt;di&gt;.&lt;jpeg|png&gt;\n</code></pre> <p>Action <code>ocr</code> - convert image files to pdf documents</p> <pre><code>in : &lt;ost&gt;_&lt;di&gt;.&lt;oft&gt;              \nor : &lt;ost&gt;_&lt;di&gt;.&lt;jpeg|png&gt;        \nout: &lt;ost&gt;_&lt;di&gt;_&lt;pn&gt;.pdf \n     &lt;ost&gt;_&lt;di&gt;_0.pdf\n</code></pre> <p>Action <code>n_2_p</code> - convert non-pdf documents to pdf documents</p> <pre><code>in : &lt;ost&gt;_&lt;di&gt;.&lt;oft&gt;              \nout: &lt;ost&gt;_&lt;di&gt;.pdf\n</code></pre> <p>Action <code>tet</code> - extract text and metadata from pdf documents</p> <pre><code>in : &lt;ost&gt;_&lt;di&gt;[_&lt;pn&gt;|_0].pdf       \nout: &lt;ost&gt;_&lt;di&gt;[_&lt;pn&gt;|_0]_line.xml        \n     &lt;ost&gt;_&lt;di&gt;[_&lt;pn&gt;|_0]_page.xml \n     &lt;ost&gt;_&lt;di&gt;[_&lt;pn&gt;|_0]_word.xml\n</code></pre> <p>Action <code>s_p_j</code> - store the parser result in a <code>JSON</code> file</p> <pre><code>in : &lt;ost&gt;_&lt;di&gt;[_&lt;pn&gt;|_0]_line.xml  \n     &lt;ost&gt;_&lt;di&gt;[_&lt;pn&gt;|_0]_page.xml        \n     &lt;ost&gt;_&lt;di&gt;[_&lt;pn&gt;|_0]_word.xml \nout: &lt;ost&gt;_&lt;di&gt;[_&lt;pn&gt;|_0]_line.json \n     &lt;ost&gt;_&lt;di&gt;[_&lt;pn&gt;|_0]_line.list_bullet.json \n     &lt;ost&gt;_&lt;di&gt;[_&lt;pn&gt;|_0]_line.list_number.json \n     &lt;ost&gt;_&lt;di&gt;[_&lt;pn&gt;|_0]_line.table.json \n     &lt;ost&gt;_&lt;di&gt;[_&lt;pn&gt;|_0]_line.toc.json \n     &lt;ost&gt;_&lt;di&gt;[_&lt;pn&gt;|_0]_page.json \n     &lt;ost&gt;_&lt;di&gt;[_&lt;pn&gt;|_0]_word.json\n</code></pre> <p>Action <code>tkn</code> - create qualified document tokens</p> <pre><code>in : &lt;ost&gt;_&lt;di&gt;[_&lt;pn&gt;|_0]_line.json \nout: &lt;ost&gt;_&lt;di&gt;[_&lt;pn&gt;|_0]_line_token.json\n</code></pre> Abbr. Meaning <code>oft</code> original file type <code>osn</code> original stem name <code>di</code> document identifier <code>pn</code> page number"},{"location":"#32-examples","title":"3.2 Examples","text":""},{"location":"#321-possible-intermediate-files-from-a-docx-document","title":"3.2.1 Possible intermediate files from a <code>docx</code> document:","text":"<pre><code>case_2_docx_route_inbox_pandoc_pdflib_2.docx\n\ncase_2_docx_route_inbox_pandoc_pdflib_2.pdf\n\ncase_2_docx_route_inbox_pandoc_pdflib_2.line.xml\ncase_2_docx_route_inbox_pandoc_pdflib_2.page.xml\ncase_2_docx_route_inbox_pandoc_pdflib_2.word.xml\n\ncase_2_docx_route_inbox_pandoc_pdflib_2.line.json\ncase_2_docx_route_inbox_pandoc_pdflib_2.line_list_bullet.json\ncase_2_docx_route_inbox_pandoc_pdflib_2.line_list_number.json\ncase_2_docx_route_inbox_pandoc_pdflib_2.line_table.json\ncase_2_docx_route_inbox_pandoc_pdflib_2.line_toc.json\ncase_2_docx_route_inbox_pandoc_pdflib_2.page.json\ncase_2_docx_route_inbox_pandoc_pdflib_2.word.json\n\ncase_2_docx_route_inbox_pandoc_pdflib_2.line.token.json\n</code></pre>"},{"location":"#322-possible-intermediate-files-from-a-jpg-document","title":"3.2.2 Possible intermediate files from a <code>jpg</code> document:","text":"<pre><code>case_6_jpg_route_inbox_tesseract_pdflib_6.jpg\n\ncase_6_jpg_route_inbox_tesseract_pdflib_6.pdf\n\ncase_6_jpg_route_inbox_tesseract_pdflib_6.line.xml\ncase_6_jpg_route_inbox_tesseract_pdflib_6.page.xml\ncase_6_jpg_route_inbox_tesseract_pdflib_6.word.xml\n\ncase_6_jpg_route_inbox_tesseract_pdflib_6.line.json\ncase_6_jpg_route_inbox_tesseract_pdflib_6.line_list_bullet.json\ncase_6_jpg_route_inbox_tesseract_pdflib_6.line_list_number.json\ncase_6_jpg_route_inbox_tesseract_pdflib_6.line_table.json\ncase_6_jpg_route_inbox_tesseract_pdflib_6.line_toc.json\ncase_6_jpg_route_inbox_tesseract_pdflib_6.page.json\ncase_6_jpg_route_inbox_tesseract_pdflib_6.word.json\n\ncase_6_jpg_route_inbox_tesseract_pdflib_6.line.token.json\n</code></pre>"},{"location":"#323-possible-intermediate-files-from-a-proper-pdf-document","title":"3.2.3 Possible intermediate files from a proper <code>pdf</code> document:","text":"<pre><code>case_3_pdf_text_route_inbox_pdflib_3.pdf\n\ncase_3_pdf_text_route_inbox_pdflib_3.line.xml\ncase_3_pdf_text_route_inbox_pdflib_3.page.xml\ncase_3_pdf_text_route_inbox_pdflib_3.word.xml\n\ncase_3_pdf_text_route_inbox_pdflib_3.line.json\ncase_3_pdf_text_route_inbox_pdflib_3.line_list_bullet.json\ncase_3_pdf_text_route_inbox_pdflib_3.line_list_number.json\ncase_3_pdf_text_route_inbox_pdflib_3.line_table.json\ncase_3_pdf_text_route_inbox_pdflib_3.line_toc.json\ncase_3_pdf_text_route_inbox_pdflib_3.page.json\ncase_3_pdf_text_route_inbox_pdflib_3.word.json\n\ncase_3_pdf_text_route_inbox_pdflib_3.line.token.json\n</code></pre>"},{"location":"#324-possible-intermediate-files-from-a-single-page-scanned-image-pdf-document","title":"3.2.4 Possible intermediate files from a single page scanned image <code>pdf</code> document:","text":"<pre><code>case_4_pdf_image_small_route_inbox_pdf2image_tesseract_pdflib_4.pdf\n\ncase_4_pdf_image_small_route_inbox_pdf2image_tesseract_pdflib_4_1.jpeg\n\ncase_4_pdf_image_small_route_inbox_pdf2image_tesseract_pdflib_4_1.pdf\n\ncase_4_pdf_image_small_route_inbox_pdf2image_tesseract_pdflib_4_1.line.xml\ncase_4_pdf_image_small_route_inbox_pdf2image_tesseract_pdflib_4_1.page.xml\ncase_4_pdf_image_small_route_inbox_pdf2image_tesseract_pdflib_4_1.word.xml\n\ncase_4_pdf_image_small_route_inbox_pdf2image_tesseract_pdflib_4_1.line.json\ncase_4_pdf_image_small_route_inbox_pdf2image_tesseract_pdflib_4_1.line_list_bullet.json\ncase_4_pdf_image_small_route_inbox_pdf2image_tesseract_pdflib_4_1.line_list_number.json\ncase_4_pdf_image_small_route_inbox_pdf2image_tesseract_pdflib_4_1.line_table.json\ncase_4_pdf_image_small_route_inbox_pdf2image_tesseract_pdflib_4_1.line_toc.json\ncase_4_pdf_image_small_route_inbox_pdf2image_tesseract_pdflib_4_1.page.json\ncase_4_pdf_image_small_route_inbox_pdf2image_tesseract_pdflib_4_1.word.json\n\ncase_4_pdf_image_small_route_inbox_pdf2image_tesseract_pdflib_4_1.line.token.json\n</code></pre>"},{"location":"#325-possible-intermediate-files-from-a-multi-page-scanned-image-pdf-document","title":"3.2.5 Possible intermediate files from a multi page scanned image <code>pdf</code> document:","text":"<pre><code>case_5_pdf_image_large_route_inbox_pdf2image_tesseract_pypdf2_pdflib_5.pdf\n\ncase_5_pdf_image_large_route_inbox_pdf2image_tesseract_pypdf2_pdflib_5_1.jpeg\ncase_5_pdf_image_large_route_inbox_pdf2image_tesseract_pypdf2_pdflib_5_2.jpeg\n\ncase_5_pdf_image_large_route_inbox_pdf2image_tesseract_pypdf2_pdflib_5_1.pdf\ncase_5_pdf_image_large_route_inbox_pdf2image_tesseract_pypdf2_pdflib_5_2.pdf\ncase_5_pdf_image_large_route_inbox_pdf2image_tesseract_pypdf2_pdflib_5_0.pdf\n\ncase_5_pdf_image_large_route_inbox_pdf2image_tesseract_pypdf2_pdflib_5_0.line.xml\ncase_5_pdf_image_large_route_inbox_pdf2image_tesseract_pypdf2_pdflib_5_0.page.xml\ncase_5_pdf_image_large_route_inbox_pdf2image_tesseract_pypdf2_pdflib_5_0.word.xml\n\ncase_5_pdf_image_large_route_inbox_pdf2image_tesseract_pypdf2_pdflib_5_0.line.json\ncase_5_pdf_image_large_route_inbox_pdf2image_tesseract_pypdf2_pdflib_5_0.line_list_bullet.json\ncase_5_pdf_image_large_route_inbox_pdf2image_tesseract_pypdf2_pdflib_5_0.line_list_number.json\ncase_5_pdf_image_large_route_inbox_pdf2image_tesseract_pypdf2_pdflib_5_0.line_table.json\ncase_5_pdf_image_large_route_inbox_pdf2image_tesseract_pypdf2_pdflib_5_0.line_toc.json\ncase_5_pdf_image_large_route_inbox_pdf2image_tesseract_pypdf2_pdflib_5_0.page.json\ncase_5_pdf_image_large_route_inbox_pdf2image_tesseract_pypdf2_pdflib_5_0.word.json\n\ncase_5_pdf_image_large_route_inbox_pdf2image_tesseract_pypdf2_pdflib_5_0.line.token.json\n</code></pre>"},{"location":"code_of_conduct/","title":"DCR - Code of Conduct","text":""},{"location":"code_of_conduct/#1-our-pledge","title":"1. Our Pledge","text":"<p>In the interest of fostering an open and welcoming environment, we as contributors and maintainers pledge to making participation in our project and our community a harassment-free experience for everyone, regardless of age, body size, disability, ethnicity, sex characteristics, gender identity and expression, level of experience, education, socio-economic status, nationality, personal appearance, race, religion, or sexual identity and orientation.</p>"},{"location":"code_of_conduct/#2-our-standards","title":"2. Our Standards","text":"<p>Examples of behavior that contributes to creating a positive environment include:</p> <ul> <li>Using welcoming and inclusive language</li> <li>Being respectful of differing viewpoints and experiences</li> <li>Gracefully accepting constructive criticism</li> <li>Focusing on what is best for the community</li> <li>Showing empathy towards other community members</li> </ul> <p>Examples of unacceptable behavior by participants include:</p> <ul> <li>The use of sexualized language or imagery and unwelcome sexual attention or  advances</li> <li>Trolling, insulting/derogatory comments, and personal or political attacks</li> <li>Public or private harassment</li> <li>Publishing others' private information, such as a physical or electronic  address, without explicit permission</li> <li>Other conduct which could reasonably be considered inappropriate in a  professional setting</li> </ul>"},{"location":"code_of_conduct/#3-our-responsibilities","title":"3. Our Responsibilities","text":"<p>Project maintainers are responsible for clarifying the standards of acceptable behavior and are expected to take appropriate and fair corrective action in response to any instances of unacceptable behavior.</p> <p>Project maintainers have the right and responsibility to remove, edit, or reject comments, commits, code, wiki edits, issues, and other contributions that are not aligned to this Code of Conduct, or to ban temporarily or permanently any contributor for other behaviors that they deem inappropriate, threatening, offensive, or harmful.</p>"},{"location":"code_of_conduct/#4-scope","title":"4. Scope","text":"<p>This Code of Conduct applies both within project spaces and in public spaces when an individual is representing the project or its community. Examples of representing a project or community include using an official project e-mail address, posting via an official social media account, or acting as an appointed representative at an online or offline event. Representation of a project may be further defined and clarified by project maintainers.</p>"},{"location":"code_of_conduct/#5-enforcement","title":"5. Enforcement","text":"<p>Instances of abusive, harassing, or otherwise unacceptable behavior may be reported by contacting the project team at info@konnexions.ch. All complaints will be reviewed and investigated and will result in a response that is deemed necessary and appropriate to the circumstances. The project team is obligated to maintain confidentiality with regard to the reporter of an incident. Further details of specific enforcement policies may be posted separately.</p> <p>Project maintainers who do not follow or enforce the Code of Conduct in good faith may face temporary or permanent repercussions as determined by other members of the project's leadership.</p>"},{"location":"code_of_conduct/#6-attribution","title":"6. Attribution","text":"<p>This Code of Conduct is adapted from the Contributor Covenant, version 1.4, available here.</p> <p>For answers to common questions about this code of conduct, see here</p>"},{"location":"contributing/","title":"DCR - Contributing Guide","text":""},{"location":"contributing/#1-license","title":"1. License","text":"<p>In case of software changes we strongly recommend you to respect the license terms.</p>"},{"location":"contributing/#2-process","title":"2. Process","text":"<ol> <li>fork it</li> <li>create your feature branch (<code>git checkout -b my-new-feature</code>)</li> <li>commit your changes (<code>git commit -am 'Add some feature'</code>)</li> <li>push to the branch (<code>git push origin my-new-feature</code>)</li> <li>create a new pull request</li> <li>Action points to be considered when adding a new database driver and / or a new programming language:<ul> <li>README.md</li> <li>Release-Notes.md</li> </ul> </li> </ol>"},{"location":"contributing/#3-notes-on-the-software-development-process","title":"3. Notes on the Software Development Process","text":"<p>See <code>Developing DCR</code> here</p>"},{"location":"developing_code_formatting/","title":"DCR - Developing - Code Formatting","text":"<p>The tools <code>Black</code>, <code>docformatter</code> and <code>isort</code> are used for formatting the programme code:</p> <ul> <li>Black - The uncompromising <code>Python</code> code formatter.</li> <li>docformatter - Formats docstrings to follow PEP 257.</li> <li>isort - A <code>Python</code> utility / library to sort imports.</li> </ul> <p>All these tools are included in the call <code>make format</code> as well as in the call <code>make dev</code>. They can be executed individually with <code>make black</code>,  <code>make pydocstyle</code> or <code>make isort</code>,  where the recommended order is first <code>make isort</code>, then <code>make black</code> and finally <code>make pydocstyle</code>.</p>"},{"location":"developing_coding_standards/","title":"DCR - Developing - Coding Standards","text":""},{"location":"developing_coding_standards/#1-python","title":"1. <code>Python</code>","text":"<ul> <li>The PEP 8 style guide for <code>Python</code> code is strictly applied and enforced with static analysis tools.</li> <li>All program code must be commented with type hinting instructions.</li> <li>All functions, modules and packages must be commented with <code>Docstring</code>.</li> <li>The program code must be covered as far as possible with appropriate tests - the aim is always 100 % test coverage.</li> <li>The successful execution of <code>make dev</code> ensures that the program code meets the required standards.</li> </ul>"},{"location":"developing_coding_standards/#2-scripts","title":"2. Scripts","text":"<ul> <li>Scripts must always be available in identical functionality for both the Unix shell <code>bash</code> and the Windows command interpreter <code>cmd.exe</code>.</li> <li>The most important dynamic parameters of a script should be requested from the user in a dialogue.</li> <li>In the event of an error, the execution of the script must be terminated immediately.</li> <li>Apart from the main scripts, all other scripts should be present in the <code>scripts</code> file directory.</li> <li>The main scripts are:<ul> <li><code>run_dcr_dev</code> - Running the DCR functionality for development purposes.</li> <li><code>run_dcr_prod</code> - Performing the DCR functionality for productive operation.</li> </ul> </li> </ul>"},{"location":"developing_continouos_delivery/","title":"DCR - Developing - Continuous Delivery","text":"<p>The GitHub Actions are used to enforce the following good practices of the software engineering process in the CI/CD process:</p> <ul> <li>uniform formatting of all source code,</li> <li>static source code analysis,</li> <li>execution of the software testing framework, and</li> <li>creation of up-to-date user documentation.</li> </ul> <p>The action <code>standards</code> in the GitHub Actions guarantees compliance with the required standards, the action <code>test_production</code> ensures error-free compilation for production use and the action <code>test_development</code> runs the tests against various operating system and <code>Python</code> versions. The actions <code>test_development</code> and <code>test_production</code> must be able to run error-free on operating system <code>Ubuntu 22.04</code> and with <code>Python</code> version <code>3.10</code>, the action <code>standards</code> is only required error-free for the latest versions of <code>Ubuntu</code> and <code>Python</code>.</p> <p>The individual steps to be carried out </p> <ol> <li> <p>in the action <code>standards</code> are:</p> <ol> <li>set up <code>Python</code>, <code>pip</code> and <code>pipenv</code></li> <li>install the development specific packages with <code>pipenv</code></li> <li>compile the <code>Python</code> code</li> <li>format the code with isort, Black and docformatter</li> <li>lint the code with Bandit, Flake8, Mypy and Pylint</li> <li>check the API docs with pydocstyle</li> <li>create and upload the user docs with Pydoc-Markdown and Mkdocs</li> <li>install Pandoc, Poppler, Tesseract OCR and TeX Live</li> <li>publish the code coverage results to <code>coveralls.io</code></li> </ol> </li> <li> <p>in the action <code>test_development</code> are:</p> <ol> <li>set up <code>Python</code>, <code>pip</code> and <code>pipenv</code></li> <li>install the <code>development</code> specific packages with <code>pipenv</code></li> <li>compile the <code>Python</code> code</li> <li>install Pandoc, Poppler, Tesseract OCR and TeX Live</li> <li>run pytest for writing better program</li> </ol> </li> <li> <p>in the action <code>test_production</code> are:</p> <ol> <li>set up <code>Python</code>, <code>pip</code> and <code>pipenv</code></li> <li>install the <code>production</code> specific packages with <code>pipenv</code></li> <li>compile the <code>Python</code> code</li> <li>install Pandoc, Poppler, Tesseract OCR and TeX Live</li> <li>run pytest for writing better program</li> </ol> </li> </ol>"},{"location":"developing_data_model/","title":"DCR - Developing - Data Model","text":""},{"location":"developing_data_model/#1-overview","title":"1. Overview","text":"<p>Data storage is realised with the relational database management system PostgreSQL.  DCR uses the official Docker image as provided by the PostgreSQL Docker Community on DockerHub - see here.  If required, a PostgreSQL Docker image can be downloaded and a PostgreSQL Docker container can be created both with the script <code>scripts/run_setup_postgresql</code>.</p>"},{"location":"developing_data_model/#2-database-schema","title":"2. Database Schema","text":""},{"location":"developing_data_model/#21-entity-relationship-er-diagram","title":"2.1 Entity-relationship (ER) Diagram","text":""},{"location":"developing_data_model/#22-database-table-action","title":"2.2 Database Table <code>action</code>","text":"<p>The database table documents all actions that have been performed on the documents.</p> <p>Example rows:</p> <p></p> <p>Example columns:</p> <p></p> <p>ER Diagram:</p> <p></p>"},{"location":"developing_data_model/#23-database-table-document","title":"2.3 Database Table <code>document</code>","text":"<p>The database table documents the current status of the document.</p> <p>Example rows:</p> <p></p> <p>Example columns:</p> <p></p> <p>ER Diagram:</p> <p></p>"},{"location":"developing_data_model/#24-database-table-language","title":"2.4 Database Table <code>language</code>","text":"<p>This database table controls the language-related document properties during processing.</p> <p>Example rows:</p> <p></p> <p>Example columns:</p> <p></p> <p>ER Diagram:</p> <p></p>"},{"location":"developing_data_model/#25-database-table-run","title":"2.5 Database Table <code>run</code>","text":"<p>This database table documents the executed processing runs in detail.</p> <p>Example rows:</p> <p></p> <p>Example columns:</p> <p></p> <p>ER Diagram:</p> <p></p>"},{"location":"developing_data_model/#26-database-table-token","title":"2.6 Database Table <code>token</code>","text":"<p>This database table contains the tokens determined by spaCy together with selected attributes.</p> <p>Example rows:</p> <p></p> <p>Example columns:</p> <p></p> <p>ER Diagram:</p> <p></p>"},{"location":"developing_data_model/#27-database-table-version","title":"2.7 Database Table <code>version</code>","text":"<p>This database table is used to monitor the version status of the DCR database schema.</p> <p>Example row:</p> <p></p> <p>Example column:</p> <p></p> <p>ER Diagram:</p> <p></p>"},{"location":"developing_development_environment/","title":"DCR - Developing - Development Environment","text":"<p>To set up a suitable development environment under <code>Ubuntu 22.04 LTS</code>, on the one hand a suitable ready-made Docker image is provided and on the other hand two scripts to create the development system in a standalone system, a virtual environment or the <code>Windows Subsystem for Linux (WSL2)</code> are available.</p>"},{"location":"developing_development_environment/#1-docker-image","title":"1. Docker Image","text":"<p>The ready-made Docker images are available on DockerHub under the following link:</p> <p>dcr_dev - Document Content Recognition Development Image</p> <p>When selecting the Docker image, care must be taken to select the appropriate version of the Docker image.</p>"},{"location":"developing_development_environment/#2-script-based-solution","title":"2. Script-based Solution","text":"<p>Alternatively, for a <code>Ubuntu 22.04 LTS</code> environment that is as unspoiled as possible, the following two scripts are available in the <code>scripts</code> file directory:</p> <ul> <li><code>scripts/0.9.7/run_install_4-vm_wsl2_1.sh</code></li> <li><code>scripts/0.9.7/run_install_4-vm_wsl2_2.sh</code></li> </ul> <p>After a <code>cd scripts</code> command in a terminal window, the script <code>run_install_4-vm_wsl2_1.sh</code> must first be executed.  Administration rights (<code>sudo</code>) are required for this.  Afterwards, the second script <code>run_install_4-vm_wsl2_2.sh</code> must be executed in a new terminal window.</p>"},{"location":"developing_software_documentation/","title":"DCR - Developing - Software Documentation","text":""},{"location":"developing_software_documentation/#1-api-documentation","title":"1. API Documentation","text":"<p>The creation of API documentation for functions, modules and packages is mandatory and enforced with the static analysis tool pydocstyle. <code>pydocstyle</code> is a static analysis tool for checking compliance with <code>Python</code> <code>Docstring</code> conventions. <code>pydocstyle</code> can be executed individually with <code>make pydocstyle</code> and is also included in both calls <code>make docs</code> and  <code>make dev</code>.</p> <p>The <code>Docstring</code> format used in DCR is that of type Google.  For Visual Studio Code, the extension VSCode Python Docstring Generator can be used when creating API documentation. With the Pydoc-Markdown tool, the API documentation is extracted from the source files and put into Markdown format.  In this format, the API documentation can then be integrated into the user documentation.</p>"},{"location":"developing_software_documentation/#2-examples-for-the-format-of-the-api-documentation","title":"2. Examples for the format of the API documentation","text":"<p>Package Documentation:</p> <pre><code>Package libs: DCR libraries.\n</code></pre> <p>Module Documentation:</p> <pre><code>Module pp.inbox: Check and distribute incoming documents.\n\nNew documents are made available in the file directory inbox.\nThese are then checked and moved to the accepted or\nrejected file directories depending on the result of the check.\nDepending on the file format, the accepted documents are then\nconverted into the pdf file format either with the help of Pandoc\nand TeX Live or with the help of Tesseract OCR.\n</code></pre> <p>Function  Documentation:</p> <pre><code>Load the command line arguments into memory.Pandoc and TeX Live\n\nThe command line arguments define the process steps to be executed.\nThe valid arguments are:\n\n    all   - Run the complete processing of all new documents.\n    db_c  - Create the database.\n    db_u  - Upgrade the database.\n    n_2_p - Convert non-pdf docuents to pdf documents.\n    ocr   - Convert image docuents to pdf documents.\n    p_i   - Process the inbox directory.\n    p_2_i - Convert pdf documents to image files.\n    tet   - Extract text from pdf documents.\n\nWith the option all, the following process steps are executed\nin this order:\n\n    1. p_i\n    2. p_2_i\n    3. n_2_p\n    4. ocr\n    5. tet\n\nArgs:\n    argv (List[str]): Command line arguments.\n\nReturns:\n    dict[str, bool]: The processing steps based on CLI arguments.\n</code></pre> <p>In Visual Studio Code, the VSCode Python Docstring Generator tool can be used to create a framework for API documentation.</p>"},{"location":"developing_software_documentation/#3-user-documentation","title":"3. User Documentation","text":"<p>The remaining documents for the user documentation can be found in the file directory <code>docs</code> in Markdown format:</p> File Headline Remarks <code>code_of_conduct.md</code> Code of Conduct <code>contributing.md</code> Contributing Guide <code>dcr_api.md</code> API Documentation <code>development.md</code> Development Notes on the software development process <code>index.md</code> Document Content Recognition Background, installation and user guide <code>license.md</code> Text of the licence agreement <code>release_history.md</code> Release History Previous release notes <code>release_notes.md</code> Release Notes Release notes of the current version <code>research.md</code> Research Reference to the relevant research papers <p>The MkDocs tool is used to create the user documentation.  With the command <code>make mkdocs</code> the user documentation is created by MkDocs and uploaded to the GitHub pages of the repository. The command <code>make mkdocs</code> is also included in the calls <code>make docs</code> and <code>make dev</code>.</p>"},{"location":"developing_software_testing/","title":"DCR - Developing - Software Testing","text":"<p>pytest is used as a software testing framework with the following plugins::</p> <ul> <li>pytest-cov for coverage reporting,</li> <li>pytest-deadfixture to list unused or duplicate fixtures, and</li> <li>pytest-random-order to randomise the order of the tests.</li> </ul> <p>On the one hand, the tests must be as complete as possible, i.e. a test coverage of 100% is aimed for, but on the other hand, the scope of the test code should be minimal, i.e. unnecessary repetitions must be strictly avoided.  The best strategy for this is to first create a test case for the normal case and then add special tests for the special cases not yet covered.</p> <p>Finally, the tool Coveralls for Python is used to enable a connection to Coveralls.</p>"},{"location":"developing_static_code_analysis/","title":"DCR - Developing - Static Code Analysis","text":"<p>The tools <code>Bandit</code>, <code>Flake8</code>, <code>Mypy</code> and <code>Pylint</code> are used for static code analysis:</p> <ul> <li>Bandit - <code>Bandit</code> is a tool designed to find common security issues in <code>Python</code> code.</li> <li>Flake8 - A <code>Python</code> tool that glues together <code>pycodestyle</code>, <code>Pyflakes</code>, <code>McCabe</code>, and third-party plugins to check the style and quality of some <code>Python</code> code.</li> <li>mypy - Optional static typing for <code>Python</code>.</li> <li>Pylint - It's not just a linter that annoys you!</li> </ul> <p>All these tools are included in the call <code>make lint</code> as well as in the call <code>make dev</code>. They can be executed individually with <code>make bandit</code>, <code>make flake8</code>, <code>make mypy</code> and <code>make pylint</code>.</p> <p><code>Flake8</code> includes the following tools:</p> <ul> <li>McCabe - McCabe complexity checker for <code>Python</code>.</li> <li>pycodestyle - Simple <code>Python</code> style checker in one <code>Python</code> file.</li> <li>Pyflakes - A simple program which checks <code>Python</code> source files for errors.</li> <li>Radon - Various code metrics for <code>Python</code> code.</li> </ul>"},{"location":"developing_system_environment/","title":"DCR - Developing - System Environment","text":"<p>DCR is developed on the operating systems <code>Ubuntu 22.04 LTS</code> and <code>Microsoft Windows 10</code>. Ubuntu is used here via the <code>VM Workstation Player 16</code>. <code>Ubuntu</code> can also be used in conjunction with the <code>Windows Subsystem for Linux (WSL2)</code>.</p> <p>The GitHub actions for continuous integration run on <code>Ubuntu 22.04</code>.</p> <p>Version <code>3.10</code> is used for the <code>Python</code> programming language.</p>"},{"location":"developing_version_planning/","title":"DCR - Developing - Version Planning","text":""},{"location":"developing_version_planning/#1-version-planning","title":"1. Version Planning","text":""},{"location":"developing_version_planning/#11-open","title":"1.1 Open","text":"Version Feature(s) 0.9.8 TBD"},{"location":"developing_version_planning/#12-already-implemented","title":"1.2 Already implemented","text":"Version Feature(s) 0.9.7 Documentation and test improvements 0.9.6 Extracting an API 0.9.3 Extending NLP capabilities 0.9.2 Refactoring database and code 0.9.1 Core text preprocessing and wrangling 0.9.0 Parser 0.8.0 PDFlib TET processing 0.7.0 Tesseract OCR processing 0.6.5 Pandoc processing 0.6.0 <code>pdf</code> for Tesseract OCR processing 0.5.0 Inbox processing"},{"location":"developing_version_planning/#2-next-development-steps","title":"2. Next Development Steps","text":""},{"location":"developing_version_planning/#21-open","title":"2.1 Open","text":""},{"location":"developing_version_planning/#211-high-priority","title":"2.1.1 High Priority","text":"<ul> <li>pandoc_dcr: convert <code>doc</code> documents to <code>docx</code></li> <li>user: reconstruct original document</li> </ul>"},{"location":"developing_version_planning/#212-normal-priority","title":"2.1.2 Normal Priority","text":"<ul> <li>API documentation: Content improvement</li> <li>API documentation: Layout improvement</li> <li>admin: reset a list of documents: clean up the database before the next process retry - delete existing data</li> <li>tool: check the content of the file directory against the database</li> <li>line type header &amp; footer:</li> <li>optional: ignore the first / last page</li> <li>optional: logging of the applied method</li> <li>optional: page number alternating in the first and last token</li> <li>optional: page number always in the first / last token</li> <li>optional: use of Levenshtein algorithm</li> <li>optional: use of language-related regular expressions to determine the header / footer with the page number</li> <li>line type table:</li> <li>check the coordinates</li> <li>table with page break</li> </ul>"},{"location":"developing_version_planning/#213-low-priority","title":"2.1.3 Low Priority","text":"<ul> <li>Google Styleguide implementation</li> </ul>"},{"location":"developing_version_planning/#22-already-implemented","title":"2.2 Already implemented","text":"<ul> <li>API Documentation</li> <li>PDFlib TET processing</li> <li>Tesseract OCR - Installation  </li> <li>all: database table 'document': new column file_size</li> <li>all: database table 'document': new column no_pages_pdf</li> <li>all: merge database table 'journal' into 'document'</li> <li>clean up the auxiliary files in file directory inbox_accepted - keep the base document</li> <li>combine <code>pdf</code> files - scanned <code>pdf</code> documents - after Tesseract OCR</li> <li>convert the appropriate documents into the <code>pdf</code> format with Pandoc and TeX Live</li> <li>duplicate handling </li> <li>error correction version 0.9.0</li> <li>error handling - highly defensive</li> <li>inbox.py - process_inbox() - processing ocr &amp; non-ocr in the same method</li> <li>introduce default language</li> <li>introduce document language - eventually inbox sub folder per language</li> <li>load initialisation data</li> <li>optionally save the original document in the database</li> <li>parser result with JSON </li> <li>parser: classify the lines, e.g. body, footer, header etc. </li> <li>replace TeX Live by LuaLaTeX or XeLuTeX (Unicode)</li> <li>test cases for file duplicate</li> </ul>"},{"location":"license/","title":"DCR - License","text":"<pre><code>                       Konnexions Public License (KX-PL)\n                           Version 2020.05, May 2020\n</code></pre> <p>pdf Version</p> <p>This license governs use of the accompanying software. If you use the software, you     accept this license. If you do not accept the license, do not use the software.</p> <ol> <li> <p>Definitions.</p> <p>The terms \"reproduce\", \"reproduction\", \"derivative works\", and \"distribution\"    have the same meaning here as under U.S. copyright law.</p> <p>A \"contribution\" is the original software, or any additions or changes to the    software.</p> <p>A \"contributor\" is any person that distributes its contribution under this    license.</p> <p>\"Licensed patents\" are a contributor's patent claims that read directly on its    contribution.</p> </li> <li> <p>Grant of Rights</p> <p>(a)  Copyright Grant - Subject to the terms of this license, including the license         conditions and limitations in section 3, each contributor grants you a non-        exclusive, worldwide, royalty-free copyright license to reproduce its         contribution, prepare derivative works of its contribution, and distribute         its contribution or any derivative works that you create.</p> <p>(b)  Patent Grant - Subject to the terms of this license, including the license         conditions and limitations in section 3, each contributor grants you a non-        exclusive, worldwide, royalty-free license under its licensed patents to         make, have made, use, sell, offer for sale, import, and/or otherwise dispose        of its contribution in the software or derivative works of the contribution         in the software.</p> </li> <li> <p>Conditions and Limitations</p> <p>(a)  No Trademark License - This license does not grant you rights to use any         contributors' name, logo, or trademarks.</p> <p>(b)  If you bring a patent claim against any contributor over patents that you         claim are infringed by the software, your patent license from such         contributor to the software ends automatically.0</p> <p>(c)  If you distribute any portion of the software, you must retain all copyright,         patent, trademark, and attribution notices that are present in the software.</p> <p>(d)  If you distribute any portion of the software in source code form, you may do        so only under this license by including a complete copy of this license with         your distribution. If you distribute any portion of the software in compiled         or object code form, you may only do so under a license that complies with         this license.</p> <p>(e)  The software is licensed \"as-is.\" You bear the risk of using it. The         contributors give no express warranties, guarantees or conditions. You may         have additional consumer rights under your local laws which this license         cannot change. To the extent permitted under your local laws, the         contributors exclude the implied warranties of merchantability, fitness for a        particular purpose and non-infringement.</p> <p>(f)  Source code usage under this License is limited to review, compilation and         contributions. Contributions to Konnexions software products under this         License may only be made in consultation with Konnexions GmbH and through the        appropriate Konnexions software repositories.</p> </li> </ol>"},{"location":"release_history/","title":"DCR - Release History","text":""},{"location":"release_history/#version-096","title":"Version 0.9.6","text":"<p>Release Date: 07.08.2022</p>"},{"location":"release_history/#1-new-features","title":"1 New Features","text":"<ul> <li>API documentation added</li> <li>Determination of bulleted lists.</li> <li>Determination of numbered lists.</li> <li>Determination of headings.</li> </ul>"},{"location":"release_history/#2-modified-features","title":"2 Modified Features","text":"<ul> <li>Code refactoring.</li> </ul>"},{"location":"release_history/#3-applied-software","title":"3 Applied Software","text":"Software Version Remark Status DBeaver 22.1.0 for virtual machine only [optional] Docker Desktop 20.10.17 base version [Docker Image &amp; VM] Git 2.25.1 base version Pandoc 2.18 PFlib TET 5.3 Poppler 0.86.1 base version Python3 3.10.6 upgrade Python3 - pip 22.1.2 Tesseract OCR 5.1.0 base version TeX Live 2019 base version TeX Live - pdfTeX 3.14159265-2.6-1.40.20 base version"},{"location":"release_history/#31-unix-specific-software","title":"3.1 Unix-specific Software","text":"Software Version Remark Status asdf v0.10.2-7e7a1fa base version (optional) cURL 7.68.0 base version dos2unix 7.4.0 base version GCC &amp; G++ 9.4.0 base version GNU Autoconf 2.69 base version GNU Automake 1.16.1 base version GNU make 4.2.1 base version htop 3.2.1 optional OpenSSL 1.1.1f base version procps 3.3.16 base version (optional) tmux 3.3a optional Ubuntu 20.04.4 LTS base version Vim 8.1.3741 base version (optional) Wget 1.20.3"},{"location":"release_history/#32-windows-specific-software","title":"3.2 Windows-specific Software","text":"Software Version Remark Status Grep for Windows 2.5.4 base version Make for Windows 3.81 base version sed for Windows 4.2.1 base version"},{"location":"release_history/#version-093","title":"Version 0.9.3","text":"<p>Release Date: 17.06.2022</p>"},{"location":"release_history/#1-new-features_1","title":"1 New Features","text":"<ul> <li>Description of the algorithms for determining the line type.</li> <li>Determination of the lines belonging to the TOC (Table of Content).</li> </ul>"},{"location":"release_history/#2-modified-features_1","title":"2 Modified Features","text":"<ul> <li>Major refactoring of the tokenizer.</li> <li>pylint: Adjustments for latest version.</li> </ul>"},{"location":"release_history/#3-applied-software_1","title":"3 Applied Software","text":"Software Version Remark Status DBeaver 22.1.0 for virtual machine only [optional] upgrade Docker Desktop 20.10.17 base version [Docker Image &amp; VM] upgrade Git 2.25.1 base version Pandoc 2.18 PFlib TET 5.3 Poppler 0.86.1 base version Python3 3.10.5 upgrade Python3 - pip 22.1.2 upgrade Tesseract OCR 5.1.0 base version TeX Live 2019 base version TeX Live - pdfTeX 3.14159265-2.6-1.40.20 base version"},{"location":"release_history/#31-unix-specific-software_1","title":"3.1 Unix-specific Software","text":"Software Version Remark Status asdf v0.10.2-7e7a1fa base version (optional) upgrade cURL 7.68.0 base version dos2unix 7.4.0 base version GCC &amp; G++ 9.4.0 base version GNU Autoconf 2.69 base version GNU Automake 1.16.1 base version GNU make 4.2.1 base version htop 3.2.1 optional upgrade OpenSSL 1.1.1f base version procps 3.3.16 base version (optional) tmux 3.3a optional upgrade Ubuntu 20.04.4 LTS base version upgrade Vim 8.1.3741 base version (optional) Wget 1.20.3"},{"location":"release_history/#32-windows-specific-software_1","title":"3.2 Windows-specific Software","text":"Software Version Remark Status Grep for Windows 2.5.4 base version Make for Windows 3.81 base version sed for Windows 4.2.1 base version"},{"location":"release_history/#version-092","title":"Version 0.9.2","text":"<p>Release Date: 01.06.2022</p>"},{"location":"release_history/#1-new-features_2","title":"1 New Features","text":"<ul> <li>object-oriented design.</li> <li>selectable spaCy token attributes completed.</li> </ul>"},{"location":"release_history/#2-modified-features_2","title":"2 Modified Features","text":"<ul> <li>database schema refactored</li> </ul>"},{"location":"release_history/#3-applied-software_2","title":"3 Applied Software","text":"Software Version Remark Status DBeaver 22.0.5 for virtual machine only [optional] upgrade Docker Desktop 20.10.16 base version [Docker Image &amp; VM] upgrade Git 2.25.1 base version Pandoc 2.18 PFlib TET 5.3 Poppler 0.86.1 base version Python3 3.10.4 Python3 - pip 22.0.4 Tesseract OCR 5.1.0 base version TeX Live 2019 base version TeX Live - pdfTeX 3.14159265-2.6-1.40.20 base version"},{"location":"release_history/#31-unix-specific-software_2","title":"3.1 Unix-specific Software","text":"Software Version Remark Status asdf v0.10.1-711ad99 base version (optional) upgrade cURL 7.68.0 base version dos2unix 7.4.0 base version GCC &amp; G++ 9.4.0 base version GNU Autoconf 2.69 base version GNU Automake 1.16.1 base version GNU make 4.2.1 base version htop 3.2.0 optional OpenSSL 1.1.1f base version procps 3.3.16 base version (optional) tmux 3.2a optional Ubuntu 20.04.4 LTS base version upgrade Vim 8.1.3741 base version (optional) Wget 1.20.3"},{"location":"release_history/#32-windows-specific-software_2","title":"3.2 Windows-specific Software","text":"Software Version Remark Status Grep for Windows 2.5.4 base version Make for Windows 3.81 base version sed for Windows 4.2.1 base version"},{"location":"release_history/#14-open-issues","title":"1.4 Open issues","text":"<ol> <li> <p>Microsoft Windows Server 2019: (see here) </p> </li> <li> <p>MkApi: (see here)</p> </li> <li> <p>Tesseract OCR: (see here)</p> </li> </ol>"},{"location":"release_history/#version-091","title":"Version 0.9.1","text":"<p>Release Date: 05.05.2022</p>"},{"location":"release_history/#1-new-features_3","title":"1. New Features","text":"<ul> <li>classification of lines into headers, footers and body lines</li> <li>support for documents in different languages - English, French, German and Italian as standard</li> <li>tokenizer based on spaCy</li> </ul>"},{"location":"release_history/#2-modified-features_3","title":"2. Modified Features","text":"<ul> <li>extending the parser to the granularities page, line and word</li> <li>refactoring to separate preprocessor and NLP specific processes</li> </ul>"},{"location":"release_history/#3-applied-software_3","title":"3. Applied Software","text":"Software Version Remark Status DBeaver 22.0.4 for virtual machine only [optional] upgrade Docker Desktop 20.10.14 base version [Docker Image &amp; VM] upgrade Git 2.25.1 base version Pandoc 2.18 upgrade PFlib TET 5.3 Poppler 0.86.1 base version Python3 3.10.4 upgrade Python3 - pip 22.0.4 Tesseract OCR 5.10.0 base version TeX Live 2019 base version TeX Live - pdfTeX 3.14159265-2.6-1.40.20 base version"},{"location":"release_history/#31-unix-specific-software_3","title":"3.1 Unix-specific Software","text":"Software Version Remark Status asdf v0.10.0-a9caa5b base version (optional) upgrade cURL 7.6.80 base version dos2unix 7.4.0 base version GCC &amp; G++ 9.4.0 base version GNU Autoconf 2.69 base version GNU Automake 1.16.1 base version GNU make 4.2.1 base version htop 3.2.0 optional upgrade OpenSSL 1.1.1f base version procps 3.3.16 base version (optional) tmux 3.2a optional Ubuntu 20.04.4 LTS base version Vim 8.1.3741 base version (optional) upgrade Wget 1.20.3"},{"location":"release_history/#32-windows-specific-software_3","title":"3.2 Windows-specific Software","text":"Software Version Remark Status Grep for Windows 2.5.4 base version Make for Windows 3.81 base version sed for Windows 4.2.1 base version"},{"location":"release_history/#version-090","title":"Version 0.9.0","text":"<p>Release Date: 06.04.2022</p>"},{"location":"release_history/#1-new-features_4","title":"1. New Features","text":"<ul> <li>support for documents in different languages - English, French, German and Italian as standard</li> </ul>"},{"location":"release_history/#2-applied-software","title":"2. Applied Software","text":"Software Version Remark Status DBeaver 22.0.2 for virtual machine only [optional] upgrade Docker Desktop 20.10.14 base version [Docker Image &amp; VM] upgrade Git 2.25.1 base version Pandoc 2.18 upgrade PFlib TET 5.3 Poppler 0.86.1 base version Python3 3.10.4 upgrade Python3 - pip 22.0.4 Tesseract OCR 5.10.0 base version TeX Live 2019 base version TeX Live - pdfTeX 3.14159265-2.6-1.40.20 base version"},{"location":"release_history/#21-unix-specific-software","title":"2.1 Unix-specific Software","text":"Software Version Remark Status asdf v0.9.0-e0d27e6 base version (optional) cURL 7.6.80 base version dos2unix 7.4.0 base version GCC &amp; G++ 9.4.0 base version GNU Autoconf 2.69 base version GNU Automake 1.16.1 base version GNU make 4.2.1 base version htop 3.1.2 optional OpenSSL 1.1.1f base version procps 3.3.16 base version (optional) tmux 3.2a optional Ubuntu 20.04.4 LTS base version Vim 8.1.2269 base version (optional) Wget 1.20.3"},{"location":"release_history/#22-windows-specific-software","title":"2.2 Windows-specific Software","text":"Software Version Remark Status Grep for Windows 2.5.4 base version Make for Windows 3.81 base version sed for Windows 4.2.1 base version"},{"location":"release_history/#version-080","title":"Version 0.8.0","text":"<p>Release Date: 18.03.2022</p>"},{"location":"release_history/#1-new-features_5","title":"1. New Features","text":"<ul> <li>processing step <code>tet</code>: Extract text from <code>pdf</code> files.</li> </ul>"},{"location":"release_history/#2-applied-software_1","title":"2. Applied Software","text":"Software Version Remark Status DBeaver 22.0.0 for virtual machine only [optional] Docker Desktop 20.10.13 base version [Docker Image &amp; VM] Git 2.25.1 base version Pandoc 2.17.1.1 PFlib TET 5.3 new Poppler 0.86.1 base version Python3 3.10.3 upgrade Python3 - pip 22.0.4 Tesseract OCR 5.10.0 base version TeX Live 2019 base version TeX Live - pdfTeX 3.14159265-2.6-1.40.20 base version"},{"location":"release_history/#21-unix-specific-software_1","title":"2.1 Unix-specific Software","text":"Software Version Remark Status asdf v0.9.0-e0d27e6 base version (optional) cURL 7.6.80 base version dos2unix 7.4.0 base version GCC &amp; G++ 9.4.0 base version GNU Autoconf 2.69 base version GNU Automake 1.16.1 base version GNU make 4.2.1 base version htop 3.1.2 optional OpenSSL 1.1.1f base version procps 3.3.16 base version (optional) tmux 3.2a optional Ubuntu 20.04.4 LTS base version Vim 8.1.2269 base version (optional) Wget 1.20.3"},{"location":"release_history/#22-windows-specific-software_1","title":"2.2 Windows-specific Software","text":"Software Version Remark Status Grep for Windows 2.5.4 base version Make for Windows 3.81 base version sed for Windows 4.2.1 base version"},{"location":"release_history/#version-070","title":"Version 0.7.0","text":"<p>Release Date: 15.03.2022</p>"},{"location":"release_history/#1-new-features_6","title":"1. New Features","text":"<ul> <li>processing step <code>ocr</code>: Convert appropriate image files to <code>pdf</code> files.</li> </ul>"},{"location":"release_history/#2-applied-software_2","title":"2. Applied Software","text":"Software Version Remark Status DBeaver 22.0.0 for virtual machine only [optional] Docker Desktop 20.10.13 base version [Docker Image &amp; VM] upgrade Git 2.25.1 base version Pandoc 2.17.1.1 Poppler 0.86.1 base version Python3 3.10.2 Python3 - pip 22.0.4 Tesseract OCR 5.10.0 base version new TeX Live 2019 base version TeX Live - pdfTeX 3.14159265-2.6-1.40.20 base version"},{"location":"release_history/#21-unix-specific-software_2","title":"2.1 Unix-specific Software","text":"Software Version Remark Status asdf v0.9.0-e0d27e6 base version (optional) cURL 7.6.80 base version dos2unix 7.4.0 base version GCC &amp; G++ 9.4.0 base version GNU Autoconf 2.69 base version GNU Automake 1.16.1 base version GNU make 4.2.1 base version htop 3.1.2 optional OpenSSL 1.1.1f base version procps 3.3.16 base version (optional) tmux 3.2a optional Ubuntu 20.04.4 LTS base version Vim 8.1.2269 base version (optional) Wget 1.20.3"},{"location":"release_history/#22-windows-specific-software_2","title":"2.2 Windows-specific Software","text":"Software Version Remark Status Grep for Windows 2.5.4 base version Make for Windows 3.81 base version sed for Windows 4.2.1 base version"},{"location":"release_history/#version-065","title":"Version 0.6.5","text":"<p>Release Date: 10.03.2022</p>"},{"location":"release_history/#1-new-features_7","title":"1. New Features","text":"<ul> <li>processing step <code>n_2_p</code>: Convert appropriate non-pdf documents to <code>pdf</code> files.</li> </ul>"},{"location":"release_history/#2-applied-software_3","title":"2. Applied Software","text":"Software Version Remark Status DBeaver 22.0.0 for virtual machine only [optional] upgrade Docker Desktop 20.10.12 base version [Docker Image &amp; VM] Git 2.25.1 base version Pandoc 2.17.1.1 new Poppler 0.86.1 base version Python3 3.10.2 Python3 - pip 22.0.4 upgrade TeX Live 2019 base version new TeX Live - pdfTeX 3.14159265-2.6-1.40.20 base version new"},{"location":"release_history/#21-unix-specific-software_3","title":"2.1 Unix-specific Software","text":"Software Version Remark Status asdf v0.9.0-e0d27e6 base version (optional) cURL 7.6.80 base version dos2unix 7.4.0 base version GCC &amp; G++ 9.4.0 base version upgrade GNU Autoconf 2.69 base version GNU Automake 1.16.1 base version GNU make 4.2.1 base version htop 3.1.2 optional OpenSSL 1.1.1f base version procps 3.3.16 base version (optional) tmux 3.2a optional Ubuntu 20.04.4 LTS base version upgrade Vim 8.1.2269 base version (optional) Wget 1.20.3"},{"location":"release_history/#22-windows-specific-software_3","title":"2.2 Windows-specific Software","text":"Software Version Remark Status Grep for Windows 2.5.4 base version Make for Windows 3.81 base version sed for Windows 4.2.1 base version"},{"location":"release_history/#version-060","title":"Version 0.6.0","text":"<p>Release Date: 04.03.2022</p>"},{"location":"release_history/#1-new-features_8","title":"1. New Features","text":"<ul> <li>Processing step <code>db_u</code>: Upgrade the database.</li> <li>Processing step <code>p_2_i</code>: Convert <code>pdf</code> documents into image files.</li> </ul>"},{"location":"release_history/#2-applied-software_4","title":"2. Applied Software","text":"Software Version Remark Status DBeaver 21.3.5 for virtual machine only [optional] Docker Desktop 20.10.12 base version [Docker Image &amp; VM] new Git 2.25.1 base version Poppler 0.86.1 base version new Python3 3.10.2 Python3 - pip 22.0.3"},{"location":"release_history/#21-unix-specific-software_4","title":"2.1 Unix-specific Software","text":"Software Version Remark Status asdf v0.9.0-e0d27e6 base version (optional) cURL 7.6.80 base version dos2unix 7.4.0 base version GCC &amp; G++ 9.3.0 base version GNU Autoconf 2.69 base version GNU Automake 1.16.1 base version GNU make 4.2.1 base version htop 3.1.2 optional OpenSSL 1.1.1f base version procps 3.3.16 base version (optional) tmux 3.2a optional Ubuntu 20.04.3 LTS base version Vim 8.1.3741 base version (optional) Wget 1.20.3"},{"location":"release_history/#22-windows-specific-software_4","title":"2.2 Windows-specific Software","text":"Software Version Remark Status Grep for Windows 2.5.4 base version new Make for Windows 3.81 base version new sed for Windows 4.2.1 base version new"},{"location":"release_history/#version-050","title":"Version 0.5.0","text":"<p>Release Date: 14.02.2022</p>"},{"location":"release_history/#1-new-features_9","title":"1. New Features","text":"<ul> <li>Setup of the entire development infrastructure</li> <li>Creation of the first version of the user documentation</li> <li>Processing of new document arrivals in the file directory <code>\u00ecnbox</code></li> </ul>"},{"location":"release_history/#2-applied-software_5","title":"2. Applied Software","text":"Software Version Remark asdf v0.9.0-e0d27e6 base version cURL 7.6.80 base version DBeaver 21.3.4 for virtual machine only dos2unix 7.4.0 base version GCC &amp; G++ 9.3.0 base version Git 2.25.1 base version GNU Autoconf 2.69 base version GNU Automake 1.16.1 base version GNU make 4.2.1 base version htop 3.1.2 OpenSSL 1.1.1f base version procps-ng 3.3.16 base version Python3 3.10.2 Python3 - pip 22.0.3 tmux 3.2a Ubuntu 20.04.3 LTS base version Vim 8.1.3741 base version Wget 1.20.3"},{"location":"release_notes/","title":"DCR - Release Notes","text":""},{"location":"release_notes/#1-version-097","title":"1. Version 0.9.7","text":"<p>Release Date: 08.03.2022</p>"},{"location":"release_notes/#11-modified-features","title":"1.1 Modified Features","text":"<ul> <li>Delimitation of the documentation to the <code>DCR</code> application</li> <li>Delimitation of the tests to the <code>DCR</code> application</li> <li>Updating the third party software used</li> </ul>"},{"location":"release_notes/#12-applied-software","title":"1.2 Applied Software","text":"Software Version Remark Status DBeaver 22.2.0 for virtual machine only [optional] upgrade Docker Desktop 20.10.17 base version [Docker Image &amp; VM] Git 2.34.1 base version upgrade Pandoc 2.19.2 upgrade PFlib TET 5.3 Poppler 22.02.0 upgrade Python3 3.10.7 upgrade Tesseract OCR 5.2.0-22-g0daf1 base version upgrade TeX Live 2022 base version upgrade"},{"location":"release_notes/#121-unix-specific-software","title":"1.2.1 Unix-specific Software","text":"Software Version Remark Status asdf v0.10.2 base version (optional) cURL 7.81.0 base version upgrade dos2unix 7.4.2 base version upgrade GCC &amp; G++ 11.2.0 base version upgrade GNU Autoconf 2.71 base version upgrade GNU Automake 1.16.5 base version upgrade GNU make 4.3 base version upgrade htop 3.2.1 optional OpenSSL 1.1.1o upgrade procps 3.3.17 base version (optional) upgrade tmux 3.3a optional Ubuntu 22.04.4 LTS base version upgrade Vim 8.2.3995 base version (optional) upgrade Wget 1.21.2 upgrade"},{"location":"release_notes/#122-windows-specific-software","title":"1.2.2 Windows-specific Software","text":"Software Version Remark Status Grep for Windows 2.5.4 base version Make for Windows 3.81 base version sed for Windows 4.2.1 base version"},{"location":"release_notes/#13-open-issues","title":"1.3 Open issues","text":"<ol> <li>Tesseract OCR: (see here)</li> </ol>"},{"location":"release_notes/#2-detailed-open-issues","title":"2. Detailed Open Issues","text":""},{"location":"release_notes/#22-tesseract-ocr","title":"2.2 Tesseract OCR","text":"<ul> <li>Issue: Images of type 'jp2': Error in pixReadStreamJp2k: version 2.3.0: differs from minor = 2 ... see #57</li> </ul> <pre><code>Issue (ocr): Converting the file 'D:\\SoftDevelopment\\Projects\\dcr\\data\\inbox_accepted\\pdf_scanned_03_ok_5.jp2' to the file 'D:\\SoftDevelopment\\Projects\\dcr\\data\\inbox_accepted\\pdf_scanned_03_ok_5.pdf' with Tesseract OCR failed - error status: '1' - error: 'Error in pixReadStreamJp2k: version 2.3.0: differs from minor = 2 Error in pixReadStream: jp2: no pix returned Error in pixRead: pix not read Error during processing.'.\n</code></pre>"},{"location":"running_configuration/","title":"DCR - Running - Configuration","text":""},{"location":"running_configuration/#1-datainitial_database_datjson","title":"1. <code>data/initial_database_dat.json</code>","text":"<p>This file contains the initial values relating to the database table <code>language</code>. The existing entries can be modified or deleted, but new entries can also be added.</p> <p>Syntax:</p> <pre><code>{\n  \"apiVersion\": \"9.9.9\",\n  \"data\": {\n    \"tables\": [\n      {\n        \"tableName\": \"language\",\n        \"rows\": [\n          {\n            \"row\": [\n              {\n                \"columnName\": \"active\",\n                \"columnValue\": true | false\n              },\n              {\n                \"columnName\": \"code_iso_639_3\",\n                \"columnValue\": \"deu\"\n              },\n              {\n                \"columnName\": \"code_spacy\",\n                \"columnValue\": \"...\"\n              },\n              {\n                \"columnName\": \"code_tesseract\",\n                \"columnValue\": \"...\"\n              },\n              {\n                \"columnName\": \"directory_name_inbox\",\n                \"columnValue\": null | \"...\"\n              },\n              {\n                \"columnName\": \"iso_language_name\",\n                \"columnValue\": \"...\"\n              }\n            ]\n          },\n          ...\n        ]\n      }\n    ]\n  }\n}\n</code></pre> <p>Example entry for a language:</p> <pre><code>{\n  \"row\": [\n    {\n      \"columnName\": \"active\",\n      \"columnValue\": false\n    },\n    {\n      \"columnName\": \"code_iso_639_3\",\n      \"columnValue\": \"fra\"\n    },\n    {\n      \"columnName\": \"code_spacy\",\n      \"columnValue\": \"fr_dep_news_trf\"\n    },\n    {\n      \"columnName\": \"code_tesseract\",\n      \"columnValue\": \"fra\"\n    },\n    {\n      \"columnName\": \"directory_name_inbox\",\n      \"columnValue\": null\n    },\n    {\n      \"columnName\": \"iso_language_name\",\n      \"columnValue\": \"French\"\n    }\n  ]\n},\n</code></pre>"},{"location":"running_configuration/#2-logging_cfgyaml","title":"2. <code>logging_cfg.yaml</code>","text":"<p>This file controls the logging behaviour of the application. </p> <p>Default content:</p> <pre><code>version: 1\n\nformatters:\n  simple:\n    format: \"%(asctime)s %(pathname)-80s ] %(levelname)-5s %(funcName)s:%(lineno)d %(message)s\"\n  extended:\n    format: \"%(asctime)s %(pathname)-80s ] %(levelname)-5s %(funcName)s:%(lineno)d \\n%(message)s\"\n\nhandlers:\n  console:\n    class: logging.StreamHandler\n    level: INFO\n    formatter: simple\n\n  file_handler:\n    class: logging.FileHandler\n    level: INFO\n    filename: logging_dcr.log\n    formatter: extended\n\nloggers:\n  dcr:\n    handlers: [ console ]\nroot:\n  handlers: [ file_handler ]\n</code></pre>"},{"location":"running_configuration/#3-setupcfg","title":"3. <code>setup.cfg</code>","text":"<p>This file controls the behaviour of the DCR application. </p> <p>The customisable entries are:</p> <pre><code>[dcr]\ndb_connection_port = 5432\ndb_connection_prefix = postgresql+psycopg2://\ndb_container_port = 5432\ndb_database = dcr_db_prod\ndb_database_admin = dcr_db_prod_admin\ndb_dialect = postgresql\ndb_host = localhost\ndb_initial_data_file = data/db_initial_data_file.json\ndb_password = postgresql\ndb_password_admin = postgresql\ndb_schema = dcr_schema\ndb_user = dcr_user\ndb_user_admin = dcr_user_admin\ndirectory_inbox_accepted = data/inbox_prod_accepted\ndirectory_inbox_rejected = data/inbox_prod_rejected\ndoc_id_in_file_name = none\nignore_duplicates = false\n</code></pre> Parameter Default value Description db_connection_port environment specific Port number the DBMS server is listening on. db_connection_prefix <code>postgresql+psycopg2://</code> Front part of the database URL. db_database environment specific DCR database name. db_database_admin environment specific Administrative database name. db_dialect <code>postgresql</code> DBMS used, currently: only PostgreSQL allowed. db_host <code>localhost</code> Host name of the DBMS server. db_initial_data_file <code>data/db_initial_data_file.json</code> File with initial database contents. db_password <code>postgresql</code> DCR database user password. db_password_admin <code>postgresql</code> Administrative database password. db_schema <code>dcr_schema</code> Database schema name. db_user <code>postgresql</code> DCR database user name. db_user_admin <code>postgresql</code> Administrative database user name. directory_inbox_accepted <code>data/inbox_prod_accepted</code> Directory for the accepted documents. directory_inbox_rejected <code>data/inbox_prod_rejected</code> Complete file name for the <code>JSON</code> file with the database initialisation data. doc_id_in_file_name <code>none</code> Position of the document id in the file name : <code>after</code>, <code>before</code> or <code>none</code>. ignore_duplicates <code>false</code> Accept presumably duplicated documents based on a SHA256 hash key. <p>The configuration parameters can be set differently for the individual environments (<code>dev</code>, <code>prod</code> and <code>test</code>).</p> <p>Examples:</p> <pre><code>[dcr.env.dev]\ndb_connection_port = 5433\ndb_database = dcr_db_dev\ndb_database_admin = dcr_db_dev_admin\ndb_initial_data_file = data/db_initial_data_file_dev.json\ndirectory_inbox_accepted = data/inbox_dev_accepted\ndirectory_inbox_rejected = data/inbox_dev_rejected\n...\n</code></pre>"},{"location":"running_document_language/","title":"DCR - Running - Document Language","text":""},{"location":"running_document_language/#1-overview","title":"1. Overview","text":"<p><code>DCR</code> supports the processing of documents in different languages.  The supported languages must be accepted by Pandoc respectively Babel, spaCy and Tesseract OCR.  Furthermore, for each of the languages in question there must be a corresponding entry in the database table <code>language</code>.</p>"},{"location":"running_document_language/#2-database-table-language","title":"2. Database Table <code>language</code>","text":"<p>The active languages in the database table <code>language</code> control the allocation of the documents to a language.  Each document language must have its own entry in this table.  The documents in a particular language are expected in the subdirectory to the <code>inbox</code> or as defined in the <code>directory_name_inbox</code> column.</p> <p>The entry for the standard language <code>English</code> is created automatically when the database is set up.  In the JSON file <code>db_initial_data_file</code>, the languages German, French and Italian are also predefined but in the inactive state.  The chosen document languages must now either be activated in this file or, if not yet available, added here. </p> <p>Example entry for the document language French:</p> <pre><code>{\n  \"row\": [\n    {\n      \"columnName\": \"active\",\n      \"columnValue\": false\n    },\n    {\n      \"columnName\": \"code_iso_639_3\",\n      \"columnValue\": \"fra\"\n    },\n    {\n      \"columnName\": \"code_pandoc\",\n      \"columnValue\": \"fr\"\n    },\n    {\n      \"columnName\": \"code_spacy\",\n      \"columnValue\": \"fr_dep_news_trf\"\n    },\n    {                                   \n      \"columnName\": \"code_tesseract\",\n      \"columnValue\": \"fra\"\n    },\n    {\n      \"columnName\": \"directory_name_inbox\",\n      \"columnValue\": null\n    },\n    {\n      \"columnName\": \"iso_language_name\",\n      \"columnValue\": \"French\"\n    }\n  ]\n},\n</code></pre> Column Description active active language - true or false code_iso_639_3 three-letter codes, the same as 639-2/T for languages, but with distinct codes for each variety of an ISO 639 macrolanguage code_pandoc the language code as used in Pandoc respectively Babel - IETF BCP 47} code_spacy the trained pipeline package as used in spaCy code_tesseract the language code as used in Tesseract OCR directory_name_inbox optional the name of the file directory relative to the <code>inbox</code> - if missing the content of the column <code>iso_language_name</code> is used iso_language_name the name of the language according to <code>ISO 639-1</code>"},{"location":"running_document_language/#3-default-document-language","title":"3. Default Document Language","text":"<p>The default document language is English.  The corresponding entry in the database table language is created internally with the following contents:</p> Column Content active true code_iso_639_3 eng code_pandoc en code_spacy en_core_web_trf code_tesseract eng directory_name_inbox the inbox directory iso_language_name English"},{"location":"running_installation/","title":"DCR - Running - Installation","text":"<ol> <li> <p>Clone or copy the DCR repository from here.</p> </li> <li> <p>Switch to the file directory DCR:</p> <p><code>cd dcr</code></p> </li> <li> <p>Install the necessary Python packages by running the script  <code>run_dcr_prod</code> with action <code>m_p</code>.</p> </li> <li> <p>Optionally, adjustments can be made in the following configuration files - details may be found here:</p> <ul> <li><code>data/db_initial_data_file.json</code>: to configure the document languages to be used</li> <li><code>logging_cfg.yaml</code>: for the logging functionality</li> <li><code>setup.cfg</code>: for the DCR application in section DCR</li> </ul> </li> <li> <p>Create a PostgreSQL database container by running the script <code>scripts/run_setup_postgresql</code> with action <code>prod</code>.</p> </li> <li> <p>Create the DCR database by running the script <code>run_dcr_prod</code> with action <code>db_c</code>.</p> </li> </ol>"},{"location":"running_operations/","title":"DCR - Running - Operations","text":"<p>DCR should be operated via the script <code>run_dcr_prod</code>.  The following actions are available:</p> Action Process <code>all</code> Run the complete processing of all new documents. <code>db_c</code> Create the database. <code>db_u</code> Upgrade the database. <code>m_d</code> Run the installation of the necessary 3rd party packages for development and run the development ecosystem. <code>m_p</code> Run the installation of the necessary 3rd party packages for production and compile all packages and modules. <code>n_2_p</code> Convert non <code>pdf</code> documents to <code>pdf</code> files. <code>ocr</code> Convert image files to <code>pdf</code> files. <code>p_2_i</code> Convert <code>pdf</code> documents to image files. <code>p_i</code> Process the inbox directory. <code>s_p_j</code> Store the parser result in a JSON file. <code>tet</code> Extract text from <code>pdf</code> documents. <code>tkn</code> Create qualified document tokens. <p>The action <code>all - run the complete processing of all new documents</code> includes the following processes in the order given:</p> Action Process <code>p_i</code> Process the inbox directory. <code>p_2_i</code> Convert <code>pdf</code> documents to image files. <code>ocr</code> Convert image files to <code>pdf</code> files. <code>n_2_p</code> Convert non <code>pdf</code> documents to <code>pdf</code> files. <code>tet</code> Extract text from <code>pdf</code> documents. <code>s_p_j</code> Store the parser result in a JSON file. <code>tkn</code> Create qualified document tokens. <p>The action <code>db_c - create the database</code> is only required once when installing <code>DCR</code>.  </p> <p>The action <code>db_u - upgrade the database</code> is necessary once for each version change of <code>DCR</code>.  </p> <p>The actions <code>m_d</code> and <code>m_p</code> correspond to the commands <code>make pipenv-dev</code> and <code>make pipenv-prod</code> for installing or updating the necessary Python libraries. </p>"},{"location":"running_requirements/","title":"DCR - Running - Requirements","text":"<p>The DCR-CORE library used in DCR determines the software required for the development and operation of DCR:</p> <ul> <li>Operating System <code>Ubuntu 22.04</code>, <code>Windows 10</code> oder <code>Windows 11</code>.</li> <li>Pandoc &amp; TeX Live</li> <li>PDFlib TET</li> <li>Poppler</li> <li>Python</li> <li>Tesseract OCR</li> </ul> <p>Further details can be found here.</p>"}]}